{
    "docs": [
        {
            "location": "/", 
            "text": "Genomics Platform Documentation\n\n\nTopics\n\n\n\n\nHPC Access\n: login and file transfer to LIMS-HPC\n\n\nHPC Archiving and Update Slides\n: Slides to go with the following documents\n\n\nHPC Archiving\n: usage of LIMS-HPC Archiving facilities\n\n\nHPC Updates\n: changes to LIMS-HPC usage", 
            "title": "Home"
        }, 
        {
            "location": "/#genomics-platform-documentation", 
            "text": "", 
            "title": "Genomics Platform Documentation"
        }, 
        {
            "location": "/#topics", 
            "text": "HPC Access : login and file transfer to LIMS-HPC  HPC Archiving and Update Slides : Slides to go with the following documents  HPC Archiving : usage of LIMS-HPC Archiving facilities  HPC Updates : changes to LIMS-HPC usage", 
            "title": "Topics"
        }, 
        {
            "location": "/hpc-access/", 
            "text": "em {font-style: normal; font-family: courier new;}\n\n\n\nHPC Access\n\n\nApplying for an account\n\n\nUser\n = task to be completed by LTU Staff/Student requiring access to LIMS-HPC.  \nLab-head\n = task to be completed by the LTU lab-head for the lab which user belongs to.\n\n\n\n\nUser\n to carefully read archive documentation:\n\n\nArchive Documentation\n\n\n\n\n\n\nUser\n to carefully read, sign and give to supervisor archive access form:\n\n\nArchive Access Form\n\n\n\n\n\n\nLab-head\n to complete an AskICT \"Unix Research Support\" request (AskICT \n Get Help \n Research Support \n Unix Research Support)\n\n\nAskLaTrobe\n\n\nif User is a staff member select \"Who requires this service?\" = \"Someone Else\" and \"Type their name in the \"Select the staff member for this server box\".  For students just leave it as \"Yourself\"\n\n\n\n\n\n\nClick \"Add attachments\" and select the Archive Access Form provided by User\n\n\nComplete the \"Description of request\" using the template below and the following replacements:\n\n\nFIRSTNAME\n: user's first/given name\n\n\nNAME\n: full name of user\n\n\nUSERNAME\n: if the user is a student then this must be their STUDENTS domain username.  Otherwise, their LTU domain username.\n\n\nEMAIL\n: the user's LTU/STUDENTS email address.  Optionally you can provide a second alternate email if they want. \n\n\nLABGROUP\n: Lab-head's surname followed by \"lab\" e.g. smithlab\n\n\n\n\n\n\n\n\n\n\n\n\nNew LIMS-HPC user for FIRSTNAME\n\nName: NAME\nUsername: USERNAME\nEmail: EMAIL\nGroup: LABGROUP\n\n\n\n\nConnecting\n\n\nClick the link below to expand the relevant instructions for your Operating System\n\n\n\n\n\n\nMac OS X / Linux\n\n\n\n\nBoth Mac OS X and Linux come with a version of ssh (called OpenSSH) that can be used from the command line.  To use OpenSSH you must \nfirst start a terminal program on your computer.  On OS X the standard terminal is called Terminal, and it is installed by default. \nOn Linux there are many popular terminal programs including: xterm, gnome-terminal, konsole (if you aren't sure, then xterm is a good \ndefault).  When you've started the terminal you should see a command prompt.  To log into LIMS-HPC, for example, type this command at \nthe prompt and press return (where the word username is replaced with your LIMS-HPC username):\n\n\n$ ssh -p 6022 username@lims-hpc-m.latrobe.edu.au\n\n\nThe same procedure works for any other machine where you have an account except that if your Unix computer uses a port other than 22 you will\nneed to specify the port by adding the option \n-p PORT\n with PORT substituted with the port number.\n\n\nYou may be presented with a message along the lines of:\n\n\nThe authenticity of host 'lims-hpc-m.latrobe.edu.au (131.172.36.150)' can't be  established.\n...\nAre you sure you want to continue connecting (yes/no)?\n\n\n\n\nAlthough you should never ignore a warning, this particular one is nothing to be concerned about; type \nyes\n and then \npress enter\n. \nIf all goes well you will be asked to enter your password.  Assuming you type the correct username and password the system should \nthen display a welcome message, and then present you with a Unix prompt.  If you get this far then you are ready to start entering \nUnix commands and thus begin using the remote computer.\n\n\n\n\n\n\n\n\n//<![CDATA[<!--\n(function(w,d,u){if(!w.$){w._delayed=true;console.info(\"Delaying JQuery calls\");w.readyQ=[];w.bindReadyQ=[];function p(x,y){if(x==\"ready\"){w.bindReadyQ.push(y);}else{w.readyQ.push(x);}};var a={ready:p,bind:p};w.$=w.jQuery=function(f){if(f===d||f===u){return a}else{p(f)}}}})(window,document)\n//-->]]>\n\n\n\n    //<![CDATA[<!--\n    $(document).ready(function(){\n        $(\"#showablelink0\").click(function(e){\n            e.preventDefault();\n            $(\"#showable0\").toggleClass(\"showable-hidden\");\n        });\n    }); //-->]]>\n    \n\n\n\n\n\n\nWindows\n\n\n\n\nOn Microsoft Windows (Vista, 7, 8) we recommend that you use the PuTTY ssh client.  PuTTY (putty.exe) can be downloaded \nfrom this web page:\n\n\nhttp://www.chiark.greenend.org.uk/~sgtatham/putty/download.html\n\n\nDocumentation for using PuTTY is here:\n\n\nhttp://www.chiark.greenend.org.uk/~sgtatham/putty/docs.html\n\n\nWhen you start PuTTY you should see a window which looks something like this:\n\n\n\n\nTo connect to LIMS-HPC you should enter \nlims-hpc-m.latrobe.edu.au\n into the box entitled \"Host Name (or IP address)\" \nand \n6022\n in the port, \nthen click on the Open button. All of the settings should remain the same as they were when PuTTY started (which should be the \nsame as they are in the picture above).\n\n\nIn some circumstances you will be presented with a window entitled PuTTY Security Alert. It will say something along the lines \nof \n\"The server's host key is not cached in the registry\"\n. This is nothing to worry about, and you should agree to continue (by \nclicking on Yes). You usually see this message the first time you try to connect to a particular remote computer.\n\n\nIf all goes well, a terminal window will open, showing a prompt with the text \n\"login as:\"\n. An example terminal window is shown \nbelow. You should type your LIMS-HPC username and press enter. After entering your username you will be prompted for your \npassword. Assuming you type the correct username and password the system should then display a welcome message, and then \npresent you with a Unix prompt. If you get this far then you are ready to start entering Unix commands and thus begin using \nthe remote computer.\n\n\n\n\n\n\n\n\n\n\n\n    //<![CDATA[<!--\n    $(document).ready(function(){\n        $(\"#showablelink1\").click(function(e){\n            e.preventDefault();\n            $(\"#showable1\").toggleClass(\"showable-hidden\");\n        });\n    }); //-->]]>\n    \n\n\nTransfer files\n\n\nClick the link below to expand the relevant instructions for your Operating System\n\n\nNote: if you are wanting to transfer files from/to another HPC system, use the Linux instructions and do it directly from either HPC \n(i.e. first login using SSH/Putty).\n\n\n\n\n\n\nMac OS X / Linux\n\n\n\n\nBoth Mac OS X and Linux come with software that enables you to transfer files to and from LIMS-HPC.  There are two commands you can\nuse: \nscp\n and \nrsync\n.  The differences are that the \nscp\n command is easier to use and \nrsync\n does some verification that transfer \nwas successful.  We will use \nscp\n here however if you want to use \nrsync\n see the \nArchiving\n page or\nthe \nrsync\n manpage.\n\n\nThe \nscp\n command works very much like the \ncp\n with the only difference being how you specify files on the remote server.\n\n\nExample filenames\n\n\n## specifying local file(s) ##\n# full path\n/home/group/mylab/mydir/myfile.txt\n# relative file\nmyfile.txt\n# relative path\nmydir/myfile.txt\n# wildcards\nmydir/*.fa\n\n## specifying a remote file ##\n# full remote path\nusername@lims-hpc-m.latrobe.edu.au:/home/group/mylab/mydir/myfile.txt\n# if your username is same on both computers you can leave it off\nlims-hpc-m.latrobe.edu.au:/home/group/mylab/mydir/myfile.txt\n# relative file (remote relative files are always relative to your home directory)\nlims-hpc-m.latrobe.edu.au:myfile.txt\nlims-hpc-m.latrobe.edu.au:../group/mylab/mydir/myfile.txt\n\n\n\n\nExample \nscp\n commands\n\n\nThe SOURCE_FILE(s) are the files that currently exist and DESTINATION_FILE_OR_DIR is where you want them to be copied.  Either the \nSOURCE or DESTINATION files can be a remote (but not both).  As with \ncp\n, if you specify multiple source files (or wildcard) the \ndestination must be an existing directory.\n\n\n# structure\nscp -P 6022 SOURCE_FILES DESTINATION_FILE_OR_DIR\n\n# example (1 file) PC to LIMS-HPC\nscp -P 6022 myfile.txt username@lims-hpc-m.latrobe.edu.au:/home/group/mylab/mydir/\n\n# example (1 file) LIMS-HPC to PC\nscp -P 6022 username@lims-hpc-m.latrobe.edu.au:/home/group/mylab/mydir/myfile.txt .\n\n# example (whole directory) PC to LIMS-HPC\nscp -P 6022 -r myfiles/ username@lims-hpc-m.latrobe.edu.au:/home/group/mylab/mydir/\n\n# example (wildcards) PC to LIMS-HPC\n# wildcards only work on source\nscp -P 6022 myfiles/*.fa username@lims-hpc-m.latrobe.edu.au:/home/group/mylab/mydir/\n\n\n\n\nNote: the port option (\n-P 6022\n) is only needed when the remote server is LIMS-HPC.  If you are transferring files to/from another HPC (from LIMS-HPC)\nyou don't need port 6022.  The default port is 22 which most HPCs use.\n\n\n\n\n\n\n\n\n\n    //<![CDATA[<!--\n    $(document).ready(function(){\n        $(\"#showablelink2\").click(function(e){\n            e.preventDefault();\n            $(\"#showable2\").toggleClass(\"showable-hidden\");\n        });\n    }); //-->]]>\n    \n\n\n\n\n\n\nWindows\n\n\n\n\nAs with connecting to LIMS-HPC, Windows requires a third party software package in order to transfer files.  We recommend that you\nuse \nWinSCP\n\n\nDownload Software\n\n\nOpen the \nWinSCP Download page\n in your browser.\n\n\nIf you have administrator access on your computer, it is best to download the \nInstallation Package\n.  However, if you are not\nthen get the \nPortable executables\n instead.\n\n\nConnecting with WinSCP\n\n\nWhen you first start WinSCP it will present you with a screen like below.\n\n\n\n\n\n\nComplete form fields\n\n\nFile protocol\n: SCP\n\n\nHost name\n: lims-hpc-m.latrobe.edu.au\n\n\nPort number\n: 6022\n\n\nUser name\n: Your LIMS-HPC username\n\n\nPassword\n: Your LIMS-HPC password\n\n\n\n\n\n\nClick \nSave\n button (so you don't need to type it in future)\n\n\n\n\n\n\n\n\nGive the session a \nSite name\n of \nLIMS-HPC\n\n\nClick \nOK\n button\n\n\nDouble-click on \nLIMS-HPC\n from the left-hand list.  In future, you can skip all above steps.\n\n\n\n\nTransferring files\n\n\nOnce connected you will be presented with a window resembling below however the files will depend on the files in your computer or \nLIMS-HPC accounts.\n\n\n\n\nThe \nleft-hand list\n of files are those on \nyour PC\n and the \nright-hand list\n are \nLIMS-HPC\n.  You can browse the directories \non each side like you would using the file explorer on your PC.\n\n\nTo transfer files from LIMS-HPC to your PC simply drag them from the right-hand list to the left-hand list.\n\n\nTo transfer files from your PC to LIMS-HPC drag them left to right.\n\n\nNote: the first time you transfer a file (or directory) you will be asked how to do it; simply accept the window (and tick the box to \nnot show in future if you want)\n\n\n\n\n\n\n\n\n\n    //<![CDATA[<!--\n    $(document).ready(function(){\n        $(\"#showablelink3\").click(function(e){\n            e.preventDefault();\n            $(\"#showable3\").toggleClass(\"showable-hidden\");\n        });\n    }); //-->]]>\n    \n\n\nAdding the HPC to your file browser\n\n\nTo avoid the command line and use the regular graphical user interface, you can add a LIMS-HPC folder to you file browser. Click the link below to expand the relevant instructions for your Operating System\n\n\n\n\n\n\nMac OS X\n\n\n\n\nNot available yet.\n\n\n\n\n\n\n\n\n\n    //<![CDATA[<!--\n    $(document).ready(function(){\n        $(\"#showablelink4\").click(function(e){\n            e.preventDefault();\n            $(\"#showable4\").toggleClass(\"showable-hidden\");\n        });\n    }); //-->]]>\n    \n\n\n\n\n\n\nLinux\n\n\n\n\nOpen your regular file browser (Nautilus in Ubuntu). On the left-hand side at the bottom click \nConnect to server\n.\n\n\nEnter the following address: sftp://username@lims-hpc-latrobe.edu.au:6022/home/username, replacing username with your LIMS-HPC username.\n\n\nClick \nConnect\n.\n\n\nEnter your password when prompted, then you can navigate your files by clicking around.\n\n\n\n\n\n\n\n\n\n    //<![CDATA[<!--\n    $(document).ready(function(){\n        $(\"#showablelink5\").click(function(e){\n            e.preventDefault();\n            $(\"#showable5\").toggleClass(\"showable-hidden\");\n        });\n    }); //-->]]>\n    \n\n\n\n\n\n\nWindows\n\n\n\n\nDownload \nSwish\n and install.\nOpen your file browser and navigate to \nComputer\n or \nThis PC\n (Windows 10). You should see an icon named \nSwish\n. Double-click on it to open.\nOn the top bar click \nAdd sftp connection\n.\n\n\n\n\nComplete form fields\n\n\nHost name\n: lims-hpc-m.latrobe.edu.au\n\n\nPort number\n: 6022\n\n\nUser name\n: Your LIMS-HPC username\n\n\nFolder\n: /home/username\n\n\n\n\n\n\nClick \nConnect\n button, and enter your LIMS-HPC password when prompted\n\n\n\n\nYou can now navigate your files by clicking around.\n\n\n\n\n\n\n\n\n\n    //<![CDATA[<!--\n    $(document).ready(function(){\n        $(\"#showablelink6\").click(function(e){\n            e.preventDefault();\n            $(\"#showable6\").toggleClass(\"showable-hidden\");\n        });\n    }); //-->]]>", 
            "title": "HPC Access"
        }, 
        {
            "location": "/hpc-access/#hpc-access", 
            "text": "", 
            "title": "HPC Access"
        }, 
        {
            "location": "/hpc-access/#applying-for-an-account", 
            "text": "User  = task to be completed by LTU Staff/Student requiring access to LIMS-HPC.   Lab-head  = task to be completed by the LTU lab-head for the lab which user belongs to.   User  to carefully read archive documentation:  Archive Documentation    User  to carefully read, sign and give to supervisor archive access form:  Archive Access Form    Lab-head  to complete an AskICT \"Unix Research Support\" request (AskICT   Get Help   Research Support   Unix Research Support)  AskLaTrobe  if User is a staff member select \"Who requires this service?\" = \"Someone Else\" and \"Type their name in the \"Select the staff member for this server box\".  For students just leave it as \"Yourself\"    Click \"Add attachments\" and select the Archive Access Form provided by User  Complete the \"Description of request\" using the template below and the following replacements:  FIRSTNAME : user's first/given name  NAME : full name of user  USERNAME : if the user is a student then this must be their STUDENTS domain username.  Otherwise, their LTU domain username.  EMAIL : the user's LTU/STUDENTS email address.  Optionally you can provide a second alternate email if they want.   LABGROUP : Lab-head's surname followed by \"lab\" e.g. smithlab       New LIMS-HPC user for FIRSTNAME\n\nName: NAME\nUsername: USERNAME\nEmail: EMAIL\nGroup: LABGROUP", 
            "title": "Applying for an account"
        }, 
        {
            "location": "/hpc-access/#connecting", 
            "text": "Click the link below to expand the relevant instructions for your Operating System    Mac OS X / Linux   Both Mac OS X and Linux come with a version of ssh (called OpenSSH) that can be used from the command line.  To use OpenSSH you must \nfirst start a terminal program on your computer.  On OS X the standard terminal is called Terminal, and it is installed by default. \nOn Linux there are many popular terminal programs including: xterm, gnome-terminal, konsole (if you aren't sure, then xterm is a good \ndefault).  When you've started the terminal you should see a command prompt.  To log into LIMS-HPC, for example, type this command at \nthe prompt and press return (where the word username is replaced with your LIMS-HPC username):  $ ssh -p 6022 username@lims-hpc-m.latrobe.edu.au  The same procedure works for any other machine where you have an account except that if your Unix computer uses a port other than 22 you will\nneed to specify the port by adding the option  -p PORT  with PORT substituted with the port number.  You may be presented with a message along the lines of:  The authenticity of host 'lims-hpc-m.latrobe.edu.au (131.172.36.150)' can't be  established.\n...\nAre you sure you want to continue connecting (yes/no)?  Although you should never ignore a warning, this particular one is nothing to be concerned about; type  yes  and then  press enter . \nIf all goes well you will be asked to enter your password.  Assuming you type the correct username and password the system should \nthen display a welcome message, and then present you with a Unix prompt.  If you get this far then you are ready to start entering \nUnix commands and thus begin using the remote computer.     //<![CDATA[<!--\n(function(w,d,u){if(!w.$){w._delayed=true;console.info(\"Delaying JQuery calls\");w.readyQ=[];w.bindReadyQ=[];function p(x,y){if(x==\"ready\"){w.bindReadyQ.push(y);}else{w.readyQ.push(x);}};var a={ready:p,bind:p};w.$=w.jQuery=function(f){if(f===d||f===u){return a}else{p(f)}}}})(window,document)\n//-->]]>  \n    //<![CDATA[<!--\n    $(document).ready(function(){\n        $(\"#showablelink0\").click(function(e){\n            e.preventDefault();\n            $(\"#showable0\").toggleClass(\"showable-hidden\");\n        });\n    }); //-->]]>\n        Windows   On Microsoft Windows (Vista, 7, 8) we recommend that you use the PuTTY ssh client.  PuTTY (putty.exe) can be downloaded \nfrom this web page:  http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html  Documentation for using PuTTY is here:  http://www.chiark.greenend.org.uk/~sgtatham/putty/docs.html  When you start PuTTY you should see a window which looks something like this:   To connect to LIMS-HPC you should enter  lims-hpc-m.latrobe.edu.au  into the box entitled \"Host Name (or IP address)\" \nand  6022  in the port, \nthen click on the Open button. All of the settings should remain the same as they were when PuTTY started (which should be the \nsame as they are in the picture above).  In some circumstances you will be presented with a window entitled PuTTY Security Alert. It will say something along the lines \nof  \"The server's host key is not cached in the registry\" . This is nothing to worry about, and you should agree to continue (by \nclicking on Yes). You usually see this message the first time you try to connect to a particular remote computer.  If all goes well, a terminal window will open, showing a prompt with the text  \"login as:\" . An example terminal window is shown \nbelow. You should type your LIMS-HPC username and press enter. After entering your username you will be prompted for your \npassword. Assuming you type the correct username and password the system should then display a welcome message, and then \npresent you with a Unix prompt. If you get this far then you are ready to start entering Unix commands and thus begin using \nthe remote computer.      \n    //<![CDATA[<!--\n    $(document).ready(function(){\n        $(\"#showablelink1\").click(function(e){\n            e.preventDefault();\n            $(\"#showable1\").toggleClass(\"showable-hidden\");\n        });\n    }); //-->]]>", 
            "title": "Connecting"
        }, 
        {
            "location": "/hpc-access/#transfer-files", 
            "text": "Click the link below to expand the relevant instructions for your Operating System  Note: if you are wanting to transfer files from/to another HPC system, use the Linux instructions and do it directly from either HPC \n(i.e. first login using SSH/Putty).    Mac OS X / Linux   Both Mac OS X and Linux come with software that enables you to transfer files to and from LIMS-HPC.  There are two commands you can\nuse:  scp  and  rsync .  The differences are that the  scp  command is easier to use and  rsync  does some verification that transfer \nwas successful.  We will use  scp  here however if you want to use  rsync  see the  Archiving  page or\nthe  rsync  manpage.  The  scp  command works very much like the  cp  with the only difference being how you specify files on the remote server.  Example filenames  ## specifying local file(s) ##\n# full path\n/home/group/mylab/mydir/myfile.txt\n# relative file\nmyfile.txt\n# relative path\nmydir/myfile.txt\n# wildcards\nmydir/*.fa\n\n## specifying a remote file ##\n# full remote path\nusername@lims-hpc-m.latrobe.edu.au:/home/group/mylab/mydir/myfile.txt\n# if your username is same on both computers you can leave it off\nlims-hpc-m.latrobe.edu.au:/home/group/mylab/mydir/myfile.txt\n# relative file (remote relative files are always relative to your home directory)\nlims-hpc-m.latrobe.edu.au:myfile.txt\nlims-hpc-m.latrobe.edu.au:../group/mylab/mydir/myfile.txt  Example  scp  commands  The SOURCE_FILE(s) are the files that currently exist and DESTINATION_FILE_OR_DIR is where you want them to be copied.  Either the \nSOURCE or DESTINATION files can be a remote (but not both).  As with  cp , if you specify multiple source files (or wildcard) the \ndestination must be an existing directory.  # structure\nscp -P 6022 SOURCE_FILES DESTINATION_FILE_OR_DIR\n\n# example (1 file) PC to LIMS-HPC\nscp -P 6022 myfile.txt username@lims-hpc-m.latrobe.edu.au:/home/group/mylab/mydir/\n\n# example (1 file) LIMS-HPC to PC\nscp -P 6022 username@lims-hpc-m.latrobe.edu.au:/home/group/mylab/mydir/myfile.txt .\n\n# example (whole directory) PC to LIMS-HPC\nscp -P 6022 -r myfiles/ username@lims-hpc-m.latrobe.edu.au:/home/group/mylab/mydir/\n\n# example (wildcards) PC to LIMS-HPC\n# wildcards only work on source\nscp -P 6022 myfiles/*.fa username@lims-hpc-m.latrobe.edu.au:/home/group/mylab/mydir/  Note: the port option ( -P 6022 ) is only needed when the remote server is LIMS-HPC.  If you are transferring files to/from another HPC (from LIMS-HPC)\nyou don't need port 6022.  The default port is 22 which most HPCs use.     \n    //<![CDATA[<!--\n    $(document).ready(function(){\n        $(\"#showablelink2\").click(function(e){\n            e.preventDefault();\n            $(\"#showable2\").toggleClass(\"showable-hidden\");\n        });\n    }); //-->]]>\n        Windows   As with connecting to LIMS-HPC, Windows requires a third party software package in order to transfer files.  We recommend that you\nuse  WinSCP  Download Software  Open the  WinSCP Download page  in your browser.  If you have administrator access on your computer, it is best to download the  Installation Package .  However, if you are not\nthen get the  Portable executables  instead.  Connecting with WinSCP  When you first start WinSCP it will present you with a screen like below.    Complete form fields  File protocol : SCP  Host name : lims-hpc-m.latrobe.edu.au  Port number : 6022  User name : Your LIMS-HPC username  Password : Your LIMS-HPC password    Click  Save  button (so you don't need to type it in future)     Give the session a  Site name  of  LIMS-HPC  Click  OK  button  Double-click on  LIMS-HPC  from the left-hand list.  In future, you can skip all above steps.   Transferring files  Once connected you will be presented with a window resembling below however the files will depend on the files in your computer or \nLIMS-HPC accounts.   The  left-hand list  of files are those on  your PC  and the  right-hand list  are  LIMS-HPC .  You can browse the directories \non each side like you would using the file explorer on your PC.  To transfer files from LIMS-HPC to your PC simply drag them from the right-hand list to the left-hand list.  To transfer files from your PC to LIMS-HPC drag them left to right.  Note: the first time you transfer a file (or directory) you will be asked how to do it; simply accept the window (and tick the box to \nnot show in future if you want)     \n    //<![CDATA[<!--\n    $(document).ready(function(){\n        $(\"#showablelink3\").click(function(e){\n            e.preventDefault();\n            $(\"#showable3\").toggleClass(\"showable-hidden\");\n        });\n    }); //-->]]>", 
            "title": "Transfer files"
        }, 
        {
            "location": "/hpc-access/#adding-the-hpc-to-your-file-browser", 
            "text": "To avoid the command line and use the regular graphical user interface, you can add a LIMS-HPC folder to you file browser. Click the link below to expand the relevant instructions for your Operating System    Mac OS X   Not available yet.     \n    //<![CDATA[<!--\n    $(document).ready(function(){\n        $(\"#showablelink4\").click(function(e){\n            e.preventDefault();\n            $(\"#showable4\").toggleClass(\"showable-hidden\");\n        });\n    }); //-->]]>\n        Linux   Open your regular file browser (Nautilus in Ubuntu). On the left-hand side at the bottom click  Connect to server .  Enter the following address: sftp://username@lims-hpc-latrobe.edu.au:6022/home/username, replacing username with your LIMS-HPC username.  Click  Connect .  Enter your password when prompted, then you can navigate your files by clicking around.     \n    //<![CDATA[<!--\n    $(document).ready(function(){\n        $(\"#showablelink5\").click(function(e){\n            e.preventDefault();\n            $(\"#showable5\").toggleClass(\"showable-hidden\");\n        });\n    }); //-->]]>\n        Windows   Download  Swish  and install.\nOpen your file browser and navigate to  Computer  or  This PC  (Windows 10). You should see an icon named  Swish . Double-click on it to open.\nOn the top bar click  Add sftp connection .   Complete form fields  Host name : lims-hpc-m.latrobe.edu.au  Port number : 6022  User name : Your LIMS-HPC username  Folder : /home/username    Click  Connect  button, and enter your LIMS-HPC password when prompted   You can now navigate your files by clicking around.     \n    //<![CDATA[<!--\n    $(document).ready(function(){\n        $(\"#showablelink6\").click(function(e){\n            e.preventDefault();\n            $(\"#showable6\").toggleClass(\"showable-hidden\");\n        });\n    }); //-->]]>", 
            "title": "Adding the HPC to your file browser"
        }, 
        {
            "location": "/hpc-archive/", 
            "text": "HPC Archiving\n\n\nThis document covers the usage of the Archiving Storage attached to LIMS-HPC.\n\n\nPurpose\n\n\nThe \nAustralian Code for the Responsible Conduct of Research\n \nrequires researchers to make use the archive storage at a research organisation (i.e. La Trobe University) and keep\nrecords about such data.  La Trobe University's policies specifically reference the Code.\n\n\nRelevant Documents\n:\n\n\n\n\nAustralian Code for the Responsible Conduct of Research\n\n\nLa Trobe University Policies\n\n\nLa Trobe University Research Data Management Policy\n\n\n\n\nGlossary\n\n\nKey terms used within this document\n\n\n\n\nProject\n: a directory of related files.  These may include multiple collections of data (i.e. multiple \n    sequencing runs) that are related.\n\n\nActive Project\n: a project that is being worked on within the last 30 days.\n\n\nInactive Project\n: a project that has ceased to be active.  This might be because of the project coming \n    to an end or being shelved for a period of time.\n\n\nMeta-data\n: information about your data.\n\n\nMeta-data file\n: In this context, a text file contained within the top level directory for each project.  The\n    purpose of this file is to store a description of the data contained within the project.\n\n\nComputational storage\n: Storage that is used within jobs (either reading/writing).\n\n\n\n\nLIMS-HPC key directories\n\n\n\n\n/home/USERNAME\n: Home directory for the user USERNAME.  No data will be stored here; only config files\n\n\n/home/group/LABGROUP\n: the directory for storing \nactive\n projects of research group LABGROUP\n\n\n/home/archive/LABGROUP\n: the directory for storing \ninactive\n projects of research group LABGROUP\n\n\n/data/genomics-archive\n: each sequencing run is stored here.  Any files within here do NOT need to be archived.  If \n    you have sequencing runs from outside providers then you can have them stored here by contacting the \n    \nGenomics Platform (genomics@latrobe.edu.au)\n  \n\n\n\n\nArchive types\n\n\nThe Archive storage on LIMS-HPC is used for storing data that is no longer being actively processed.  There are two\ngroups of archived projects: \n\n\nPublished\n\n\nData analysis that has been published (or is under review).  This data must be cleaned, compressed and have a COMPLETE\nmeta-data file.  Once the project is ready it will be \nlocked\n so that no users can add, change or delete the files within \nit.  A locked project will only be readable for researchers within the labgroup and not changeable.  A \nsupplementary\n \nsub-directory for each project is used for adding new files/information after the project is locked.  Files within here will\nalso be locked when ready.\n\n\nShelved\n\n\nFor projects that have been put on hold for the time being.  They can be brought back to the HPC storage (i.e. \n/home/group/*) when work resumes.\n\n\nArchive directory layout\n\n\nEach labgroup's archive directory contains two sub-directories for the Published and Shelved data.\n\n\n\n\n/home/archive/LABGROUP/pub\n: Research projects that result in published data are stored inside the \npub\n directory\n\n\n/home/archive/LABGROUP/shelf\n: Research projects that are temporarily shelved are stored inside the \nshelf\n directory\n\n\n\n\nMeta-data\n\n\nItems that must be included as a minimum in archived data (metadata.txt)\n\n\n\n\nContacts\n: Phone, email addresses, department of:\n\n\nPrimary\n: the researchers who created the results/performed research.\n\n\nSupervisor/lab group\n:\n\n\nCollaborators\n: Internal and external\n\n\n\n\n\n\nApprovals\n:\n\n\nIncoming\n: A list of approvals that were received by you for use of external data if any. (attach email text if \n  coming via email, best for forward the email then copy all text so it includes the from/to fields)\n\n\nOutgoing\n: A list of approvals that you have given out for other copies of this research data including contact \n  details and names of persons and for what purpose they were given.\n\n\n\n\n\n\nConfidentiality/Ethics restrictions\n:\n\n\nAre there any restrictions on the confidentiality of all or parts of this data.  Which parts if any can be given \n  out to others if a request comes from publication?\n\n\n\n\n\n\nExpiry\n:  NOTE: data should only be deleted if it has no useful purpose.  If the expiry data comes around and it's \n  still useful then a new expiry should be set\n\n\nWhat date should this data be deleted (See section 2.1.1 of r39 of the \"AUSTRALIAN CODE FOR THE RESPONSIBLE CONDUCT \n  OF RESEARCH\" for minimum time frames required).\n\n\nWho is responsible for the disposal (or extension)\n\n\nNote any challenges or allegations of research misconduct that are raised against this research.  While unresolved\n  cases remain the results MUST NOT be deleted.\n\n\n\n\n\n\nReferences\n:\n\n\nLab books and other documentation that describes the data processing and/or wet lab work associated with this data.\n\n\nPublications\n: Citation and doi/url for any publications that are a result of this data\n\n\n\n\n\n\n\n\nmetadata.txt\n: a template file to use for your projects metadata.txt\n\n\nWhat to keep\n\n\n\n\nData-wise\n, the code says you need to keep at least the raw input files, the output results and anything that is not possible to \nreproduce in your data analysis.  You might also want to keep any intermediate results that take a significant time to reproduce.\nAny dataset that you download from the web to use in your analysis should be archived with your results as it might be hard to\nrecreate the dataset in the future (if the web resource disappears or changes).\n\n\nMeta-data\n wise, you need to keep all meta-data which includes all your job scripts for each step of your analysis.\n\n\nDon't keep SAM files particularly if you have BAM files of the same contents.  When developing your processing pipeline consider\na method which produces BAM files directly if possible.\n\n\nCopying data\n\n\nPreparation\n\n\nPrior to transferring you need to cleanup the project directory.  See the \nBest Practices\n section below for the tasks that should\nbe completed. \n\n\nAll FASTQ/A files should be compressed as do any other large text files.  When you compress a text file that wasn't compressed when \nyou ran pipeline make sure you document that it was done in a README file so that you remember to decompress it if you need to \nperform processing again.\n\n\nTransferring\n\n\nYou should transfer the prepared project by 'copying' it rather then 'moving' it; the archive storage is on a separate filesystem\nso there is no speed advantage by 'moving' it.  Worse, if the transfer fails part way through the 'move', it is much harder to \ncontinue afterwards.\n\n\nGiven that both the archive and computational storage are 'mounted' to the LIMS-HPC filesystem (i.e. you can access it by a regular \nunix path), you could use the standard unix \ncp\n command however this is discouraged.  The most reliable (and best tool to recover)\nis to use the \nrsync\n command.  e.g.\n\n\n#!/bin/bash\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=1\n#SBATCH --mem-per-cpu=1024\n#SBATCH --partition=compute\n#SBATCH --time=2-0\n\necho \nStarting: $(date)\n\n\n# perform copy\nrsync -avP PROJECT_DIR_NAME /home/archive/LABGROUP/pub/\n\necho \nFinished: $(date)\n\n\n\n\n\nThe manpage description of the \n-avP\n flags are:\n\n\n        -a, --archive               archive mode; equals -rlptgoD (no -H,-A,-X)\n        -r, --recursive             recurse into directories\n        -l, --links                 copy symlinks as symlinks\n        -p, --perms                 preserve permissions\n        -t, --times                 preserve modification times\n        -g, --group                 preserve group\n        -o, --owner                 preserve owner (super-user only)\n        -D                          same as --devices --specials\n            --devices               preserve device files (super-user only)\n            --specials              preserve special files\n        -v, --verbose               increase verbosity\n        -P                          same as --partial --progress\n            --partial               keep partially transferred files\n            --progress              show progress during transfer\n\n\n\n\nWhich can roughly be translated to \n'make an exact copy of our project, resume if we have started before and tell us in \ndetail what was done'\n\n\nData disposal\n\n\nData must only be disposed of in accordance with the La Trobe \nResearch Data Retention and Disposal \nPolicy\n and any other relevant \npolicies.\n\n\nAdditionally, when a dataset is disposed of, the project directory and metadata file must remain.  A note should be added to \nthe metadata file indicating the date, whom and reason it was deleted.  A full directory listing should be stored prior to\ndeletion:\n\n\nls -lR \n listing.txt\n\n\n\n\nProject best practice\n\n\nTo help produce repeatable science and make your life easier when it comes time to archive here are a number of suggestions\nto use while working on a project.\n\n\nEach step in its own directory\n\n\nWithin each project there are commonly multiple processing steps used.  It's best practice to create a sub-directory for each\nstep in your analysis.  This helps reduce the confusion about files and makes it easier to cleanup and archive.  If you add a \nsequence number to the beginning they order correctly with \nls\n \n\n\nClean as you go\n\n\nOnce you have successfully completed a step in your analysis you should remove any files resulting from earlier failed\nanalysis.\n\n\nBetter yet, move all files from this step out of the way (i.e. to a subdirectory called 'old') and repeat the steps you used to\nachieve a successful result.  This makes sure you are able to repeat the analysis.  When finished you can remove the old files.\n\n\nMaintain metadata.txt\n\n\nCreate the metadata.txt file when you start a project and complete it as you go along.  As a minimum you should put your contact\ndetails in there and document the source (and any approvals for) data.\n\n\nDon't link between projects\n\n\nYou should resist the urge to create links from one project to another as this will result in dead links if one project is\narchived before another.  If two projects share the same data then you can apply to have the data stored in the genomics platform\narchive and link to it there.\n\n\nBackground\n\n\nWhen using data within your project it's best practice to use \nsymbolic links\n to grab the source data from the genomics platform\narchive instead of making a copy to your project.  There are two types of \nsymbolic links\n: (1) relative and (2) absolute and are \ndifferentiated by whether you use a relative path or absolute path when creating the link.\n\n\nWhen should you use each\n?\n\n\n\n\nAbsolute\n: When linking to files or directories outside of the current project directory.  e.g. linking your nextgen sequence\n  data to your projects source data. \n\n\nmkdir 00-raw; \ncd 00-raw; \nln -s /data/genomics-archive/RUNID/Unaligned/sample1.fq.gz .\n\n\nRelative\n: When linking to files or directories inside your current project.  e.g. you might want to create a subset of your\n  samples for testing.  This would allow you to use a file regex to select the input files to your command \"\ntestset/*.fq.gz\n\"\n\n\ncd 00-raw; \nmkdir testset; \ncd testset; \nln -s ../sample2.fq.gz .\n\n\n\n\nRead-only\n\n\nIt's a good idea to make your files read-only once they are successful to help prevent data-loss when you do a recursive delete\nin the wrong place.  NOTE: this will NOT protect you from the rm -f.\n\n\n# individual file(s)\nchmod a-w FILENAME\n\n# whole directory\nchmod a-w -R DIRECTORYNAME\n\n\n\n\nAnother helpful hint is to create a file named '0' in directories that contain valuable files and make this read-only.  This will\ncause \nrm -r ...\n to prompt before deleting it so if you accidentally try to delete the directory then this can help save you (by\npressing \nCTRL + C\n to terminate the command). \n\n\ntouch 0; chmod a-w 0;", 
            "title": "HPC Archiving"
        }, 
        {
            "location": "/hpc-archive/#hpc-archiving", 
            "text": "This document covers the usage of the Archiving Storage attached to LIMS-HPC.", 
            "title": "HPC Archiving"
        }, 
        {
            "location": "/hpc-archive/#purpose", 
            "text": "The  Australian Code for the Responsible Conduct of Research  \nrequires researchers to make use the archive storage at a research organisation (i.e. La Trobe University) and keep\nrecords about such data.  La Trobe University's policies specifically reference the Code.  Relevant Documents :   Australian Code for the Responsible Conduct of Research  La Trobe University Policies  La Trobe University Research Data Management Policy", 
            "title": "Purpose"
        }, 
        {
            "location": "/hpc-archive/#glossary", 
            "text": "Key terms used within this document   Project : a directory of related files.  These may include multiple collections of data (i.e. multiple \n    sequencing runs) that are related.  Active Project : a project that is being worked on within the last 30 days.  Inactive Project : a project that has ceased to be active.  This might be because of the project coming \n    to an end or being shelved for a period of time.  Meta-data : information about your data.  Meta-data file : In this context, a text file contained within the top level directory for each project.  The\n    purpose of this file is to store a description of the data contained within the project.  Computational storage : Storage that is used within jobs (either reading/writing).", 
            "title": "Glossary"
        }, 
        {
            "location": "/hpc-archive/#lims-hpc-key-directories", 
            "text": "/home/USERNAME : Home directory for the user USERNAME.  No data will be stored here; only config files  /home/group/LABGROUP : the directory for storing  active  projects of research group LABGROUP  /home/archive/LABGROUP : the directory for storing  inactive  projects of research group LABGROUP  /data/genomics-archive : each sequencing run is stored here.  Any files within here do NOT need to be archived.  If \n    you have sequencing runs from outside providers then you can have them stored here by contacting the \n     Genomics Platform (genomics@latrobe.edu.au)", 
            "title": "LIMS-HPC key directories"
        }, 
        {
            "location": "/hpc-archive/#archive-types", 
            "text": "The Archive storage on LIMS-HPC is used for storing data that is no longer being actively processed.  There are two\ngroups of archived projects:", 
            "title": "Archive types"
        }, 
        {
            "location": "/hpc-archive/#published", 
            "text": "Data analysis that has been published (or is under review).  This data must be cleaned, compressed and have a COMPLETE\nmeta-data file.  Once the project is ready it will be  locked  so that no users can add, change or delete the files within \nit.  A locked project will only be readable for researchers within the labgroup and not changeable.  A  supplementary  \nsub-directory for each project is used for adding new files/information after the project is locked.  Files within here will\nalso be locked when ready.", 
            "title": "Published"
        }, 
        {
            "location": "/hpc-archive/#shelved", 
            "text": "For projects that have been put on hold for the time being.  They can be brought back to the HPC storage (i.e. \n/home/group/*) when work resumes.", 
            "title": "Shelved"
        }, 
        {
            "location": "/hpc-archive/#archive-directory-layout", 
            "text": "Each labgroup's archive directory contains two sub-directories for the Published and Shelved data.   /home/archive/LABGROUP/pub : Research projects that result in published data are stored inside the  pub  directory  /home/archive/LABGROUP/shelf : Research projects that are temporarily shelved are stored inside the  shelf  directory", 
            "title": "Archive directory layout"
        }, 
        {
            "location": "/hpc-archive/#meta-data", 
            "text": "Items that must be included as a minimum in archived data (metadata.txt)   Contacts : Phone, email addresses, department of:  Primary : the researchers who created the results/performed research.  Supervisor/lab group :  Collaborators : Internal and external    Approvals :  Incoming : A list of approvals that were received by you for use of external data if any. (attach email text if \n  coming via email, best for forward the email then copy all text so it includes the from/to fields)  Outgoing : A list of approvals that you have given out for other copies of this research data including contact \n  details and names of persons and for what purpose they were given.    Confidentiality/Ethics restrictions :  Are there any restrictions on the confidentiality of all or parts of this data.  Which parts if any can be given \n  out to others if a request comes from publication?    Expiry :  NOTE: data should only be deleted if it has no useful purpose.  If the expiry data comes around and it's \n  still useful then a new expiry should be set  What date should this data be deleted (See section 2.1.1 of r39 of the \"AUSTRALIAN CODE FOR THE RESPONSIBLE CONDUCT \n  OF RESEARCH\" for minimum time frames required).  Who is responsible for the disposal (or extension)  Note any challenges or allegations of research misconduct that are raised against this research.  While unresolved\n  cases remain the results MUST NOT be deleted.    References :  Lab books and other documentation that describes the data processing and/or wet lab work associated with this data.  Publications : Citation and doi/url for any publications that are a result of this data     metadata.txt : a template file to use for your projects metadata.txt", 
            "title": "Meta-data"
        }, 
        {
            "location": "/hpc-archive/#what-to-keep", 
            "text": "Data-wise , the code says you need to keep at least the raw input files, the output results and anything that is not possible to \nreproduce in your data analysis.  You might also want to keep any intermediate results that take a significant time to reproduce.\nAny dataset that you download from the web to use in your analysis should be archived with your results as it might be hard to\nrecreate the dataset in the future (if the web resource disappears or changes).  Meta-data  wise, you need to keep all meta-data which includes all your job scripts for each step of your analysis.  Don't keep SAM files particularly if you have BAM files of the same contents.  When developing your processing pipeline consider\na method which produces BAM files directly if possible.", 
            "title": "What to keep"
        }, 
        {
            "location": "/hpc-archive/#copying-data", 
            "text": "", 
            "title": "Copying data"
        }, 
        {
            "location": "/hpc-archive/#preparation", 
            "text": "Prior to transferring you need to cleanup the project directory.  See the  Best Practices  section below for the tasks that should\nbe completed.   All FASTQ/A files should be compressed as do any other large text files.  When you compress a text file that wasn't compressed when \nyou ran pipeline make sure you document that it was done in a README file so that you remember to decompress it if you need to \nperform processing again.", 
            "title": "Preparation"
        }, 
        {
            "location": "/hpc-archive/#transferring", 
            "text": "You should transfer the prepared project by 'copying' it rather then 'moving' it; the archive storage is on a separate filesystem\nso there is no speed advantage by 'moving' it.  Worse, if the transfer fails part way through the 'move', it is much harder to \ncontinue afterwards.  Given that both the archive and computational storage are 'mounted' to the LIMS-HPC filesystem (i.e. you can access it by a regular \nunix path), you could use the standard unix  cp  command however this is discouraged.  The most reliable (and best tool to recover)\nis to use the  rsync  command.  e.g.  #!/bin/bash\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=1\n#SBATCH --mem-per-cpu=1024\n#SBATCH --partition=compute\n#SBATCH --time=2-0\n\necho  Starting: $(date) \n\n# perform copy\nrsync -avP PROJECT_DIR_NAME /home/archive/LABGROUP/pub/\n\necho  Finished: $(date)   The manpage description of the  -avP  flags are:          -a, --archive               archive mode; equals -rlptgoD (no -H,-A,-X)\n        -r, --recursive             recurse into directories\n        -l, --links                 copy symlinks as symlinks\n        -p, --perms                 preserve permissions\n        -t, --times                 preserve modification times\n        -g, --group                 preserve group\n        -o, --owner                 preserve owner (super-user only)\n        -D                          same as --devices --specials\n            --devices               preserve device files (super-user only)\n            --specials              preserve special files\n        -v, --verbose               increase verbosity\n        -P                          same as --partial --progress\n            --partial               keep partially transferred files\n            --progress              show progress during transfer  Which can roughly be translated to  'make an exact copy of our project, resume if we have started before and tell us in \ndetail what was done'", 
            "title": "Transferring"
        }, 
        {
            "location": "/hpc-archive/#data-disposal", 
            "text": "Data must only be disposed of in accordance with the La Trobe  Research Data Retention and Disposal \nPolicy  and any other relevant \npolicies.  Additionally, when a dataset is disposed of, the project directory and metadata file must remain.  A note should be added to \nthe metadata file indicating the date, whom and reason it was deleted.  A full directory listing should be stored prior to\ndeletion:  ls -lR   listing.txt", 
            "title": "Data disposal"
        }, 
        {
            "location": "/hpc-archive/#project-best-practice", 
            "text": "To help produce repeatable science and make your life easier when it comes time to archive here are a number of suggestions\nto use while working on a project.", 
            "title": "Project best practice"
        }, 
        {
            "location": "/hpc-archive/#each-step-in-its-own-directory", 
            "text": "Within each project there are commonly multiple processing steps used.  It's best practice to create a sub-directory for each\nstep in your analysis.  This helps reduce the confusion about files and makes it easier to cleanup and archive.  If you add a \nsequence number to the beginning they order correctly with  ls", 
            "title": "Each step in its own directory"
        }, 
        {
            "location": "/hpc-archive/#clean-as-you-go", 
            "text": "Once you have successfully completed a step in your analysis you should remove any files resulting from earlier failed\nanalysis.  Better yet, move all files from this step out of the way (i.e. to a subdirectory called 'old') and repeat the steps you used to\nachieve a successful result.  This makes sure you are able to repeat the analysis.  When finished you can remove the old files.", 
            "title": "Clean as you go"
        }, 
        {
            "location": "/hpc-archive/#maintain-metadatatxt", 
            "text": "Create the metadata.txt file when you start a project and complete it as you go along.  As a minimum you should put your contact\ndetails in there and document the source (and any approvals for) data.", 
            "title": "Maintain metadata.txt"
        }, 
        {
            "location": "/hpc-archive/#dont-link-between-projects", 
            "text": "You should resist the urge to create links from one project to another as this will result in dead links if one project is\narchived before another.  If two projects share the same data then you can apply to have the data stored in the genomics platform\narchive and link to it there.", 
            "title": "Don't link between projects"
        }, 
        {
            "location": "/hpc-archive/#background", 
            "text": "When using data within your project it's best practice to use  symbolic links  to grab the source data from the genomics platform\narchive instead of making a copy to your project.  There are two types of  symbolic links : (1) relative and (2) absolute and are \ndifferentiated by whether you use a relative path or absolute path when creating the link.  When should you use each ?   Absolute : When linking to files or directories outside of the current project directory.  e.g. linking your nextgen sequence\n  data to your projects source data.   mkdir 00-raw; \ncd 00-raw; \nln -s /data/genomics-archive/RUNID/Unaligned/sample1.fq.gz .  Relative : When linking to files or directories inside your current project.  e.g. you might want to create a subset of your\n  samples for testing.  This would allow you to use a file regex to select the input files to your command \" testset/*.fq.gz \"  cd 00-raw; \nmkdir testset; \ncd testset; \nln -s ../sample2.fq.gz .", 
            "title": "Background"
        }, 
        {
            "location": "/hpc-archive/#read-only", 
            "text": "It's a good idea to make your files read-only once they are successful to help prevent data-loss when you do a recursive delete\nin the wrong place.  NOTE: this will NOT protect you from the rm -f.  # individual file(s)\nchmod a-w FILENAME\n\n# whole directory\nchmod a-w -R DIRECTORYNAME  Another helpful hint is to create a file named '0' in directories that contain valuable files and make this read-only.  This will\ncause  rm -r ...  to prompt before deleting it so if you accidentally try to delete the directory then this can help save you (by\npressing  CTRL + C  to terminate the command).   touch 0; chmod a-w 0;", 
            "title": "Read-only"
        }, 
        {
            "location": "/hpc-update/", 
            "text": "HPC Updates\n\n\nThis document covers changes to the way we use LIMS-HPC\n\n\nGroup directories\n\n\nThere are group directories for every user on the system.  They are located in the /home/group/LABGROUP \nwhere LABGROUP is usually the labhead's surname followed by 'lab'  e.g. /home/group/whelanlab.  Each lab \ngroup is restricted to only users who are in the labgroup.\n\n\nNo home dir data\n\n\nNo data should be stored or processed within your home directory (e.g. /home/USERNAME).  While it works, \nit makes it difficult to cleanup/archive and for you to get help debugging your work.\n\n\nFair usage\n\n\nPlease be fair and not request more that 32 cores.\n\n\nPartitions\n\n\n\n\n8hour\n: For small jobs requiring less than 8 hours of time to compute.  You should not use more than \n  8 cores.  It has access to all nodes of the HPC so should always be able to run a job (unless it's \n  really busy)\n\n\nCompute\n: Regular jobs up to 7 days of compute.  It has access to most nodes.\n\n\nLong\n: For jobs that are going to take a long time to complete; maximum is 200 days\n\n\nBigmem\n: For jobs that require more than 128GB of memory (and hence need node 1)\n\n\n\n\nTime extensions\n\n\nI can extend your jobs time setting if it looks like it won't finish in time up to 2x the maximum for its \nqueue.  The exception to this is Node 1 which I will not extend as it is a specialist node and needs to be \navailable for bigmem jobs.  To get this, please email your job number and expected time it will require to \nGenomics Platform \ngenomics@latrobe.edu.au\n\n\nNTasks\n\n\nThe \n--ntasks\n option regularly gets used instead of \n--cpus-per-task\n.  If you are running programs one \nat a time then you should be using \n--cpus-per-task\n.  While it may produce the same result, the \nconsequence of using \n--ntasks\n is that SLURM could give you some CPUs on one node and the rest on another\nwhich your scripts are not likely to be able to support.\n\n\n#!/bin/bash\n#SBATCH --share\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=8\n#SBATCH --mem-per-cpu=1024\n#SBATCH --partition=8hour\n#SBATCH --time=08:00\n\necho \nStarting: $(date)\n\n\nsome-awesome-program --threads=8 input.fa \n output.txt\n\necho \nFinished: $(date)\n\n\n\n\n\nFigure\n: example slurm script requesting 8 cores on a single node, for 8 hours, with 8GB of memory\n\n\nJob monitoring\n\n\nMunin\n\n\nMunin is a webpage that shows graphs CPU usage over time.  It can be accessed from the following webpage:\n\n\nhttp://munin-lims.latrobe.edu.au/lims-hpc.html\n\n\nIt is good for tracking how your job used the CPU over time however it only shows the whole node usage so \nin some situations it is hard to tell who used what.\n\n\nIf you click on one the graphs you can see the usage over longer time frames.\n\n\nTop\n\n\ntop\n us a unix command that shows the current usage of CPU and Memory of each process running on the current\nnode.  You will need to login to the compute nodes to see your job's usage.  See the \"Topic 4: Job Monitoring\" \nsection in the \nHPC Workshop material\n \nfor more details on using top.  To setup node login see \nLIMS-HPC Node Login Setup\n\n\nIs it correct?\n\n\nMake sure you check your job is running correctly when it starts and at regular intervals.", 
            "title": "HPC Updates"
        }, 
        {
            "location": "/hpc-update/#hpc-updates", 
            "text": "This document covers changes to the way we use LIMS-HPC", 
            "title": "HPC Updates"
        }, 
        {
            "location": "/hpc-update/#group-directories", 
            "text": "There are group directories for every user on the system.  They are located in the /home/group/LABGROUP \nwhere LABGROUP is usually the labhead's surname followed by 'lab'  e.g. /home/group/whelanlab.  Each lab \ngroup is restricted to only users who are in the labgroup.", 
            "title": "Group directories"
        }, 
        {
            "location": "/hpc-update/#no-home-dir-data", 
            "text": "No data should be stored or processed within your home directory (e.g. /home/USERNAME).  While it works, \nit makes it difficult to cleanup/archive and for you to get help debugging your work.", 
            "title": "No home dir data"
        }, 
        {
            "location": "/hpc-update/#fair-usage", 
            "text": "Please be fair and not request more that 32 cores.", 
            "title": "Fair usage"
        }, 
        {
            "location": "/hpc-update/#partitions", 
            "text": "8hour : For small jobs requiring less than 8 hours of time to compute.  You should not use more than \n  8 cores.  It has access to all nodes of the HPC so should always be able to run a job (unless it's \n  really busy)  Compute : Regular jobs up to 7 days of compute.  It has access to most nodes.  Long : For jobs that are going to take a long time to complete; maximum is 200 days  Bigmem : For jobs that require more than 128GB of memory (and hence need node 1)", 
            "title": "Partitions"
        }, 
        {
            "location": "/hpc-update/#time-extensions", 
            "text": "I can extend your jobs time setting if it looks like it won't finish in time up to 2x the maximum for its \nqueue.  The exception to this is Node 1 which I will not extend as it is a specialist node and needs to be \navailable for bigmem jobs.  To get this, please email your job number and expected time it will require to \nGenomics Platform  genomics@latrobe.edu.au", 
            "title": "Time extensions"
        }, 
        {
            "location": "/hpc-update/#ntasks", 
            "text": "The  --ntasks  option regularly gets used instead of  --cpus-per-task .  If you are running programs one \nat a time then you should be using  --cpus-per-task .  While it may produce the same result, the \nconsequence of using  --ntasks  is that SLURM could give you some CPUs on one node and the rest on another\nwhich your scripts are not likely to be able to support.  #!/bin/bash\n#SBATCH --share\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=8\n#SBATCH --mem-per-cpu=1024\n#SBATCH --partition=8hour\n#SBATCH --time=08:00\n\necho  Starting: $(date) \n\nsome-awesome-program --threads=8 input.fa   output.txt\n\necho  Finished: $(date)   Figure : example slurm script requesting 8 cores on a single node, for 8 hours, with 8GB of memory", 
            "title": "NTasks"
        }, 
        {
            "location": "/hpc-update/#job-monitoring", 
            "text": "", 
            "title": "Job monitoring"
        }, 
        {
            "location": "/hpc-update/#munin", 
            "text": "Munin is a webpage that shows graphs CPU usage over time.  It can be accessed from the following webpage:  http://munin-lims.latrobe.edu.au/lims-hpc.html  It is good for tracking how your job used the CPU over time however it only shows the whole node usage so \nin some situations it is hard to tell who used what.  If you click on one the graphs you can see the usage over longer time frames.", 
            "title": "Munin"
        }, 
        {
            "location": "/hpc-update/#top", 
            "text": "top  us a unix command that shows the current usage of CPU and Memory of each process running on the current\nnode.  You will need to login to the compute nodes to see your job's usage.  See the \"Topic 4: Job Monitoring\" \nsection in the  HPC Workshop material  \nfor more details on using top.  To setup node login see  LIMS-HPC Node Login Setup", 
            "title": "Top"
        }, 
        {
            "location": "/hpc-update/#is-it-correct", 
            "text": "Make sure you check your job is running correctly when it starts and at regular intervals.", 
            "title": "Is it correct?"
        }, 
        {
            "location": "/materials/", 
            "text": "Supporting materials for workshops\n\n\nCLC Genomics\n\n\n\n\nSlides 1\n\n\nSlides 2", 
            "title": "Support files"
        }, 
        {
            "location": "/materials/#supporting-materials-for-workshops", 
            "text": "", 
            "title": "Supporting materials for workshops"
        }, 
        {
            "location": "/materials/#clc-genomics", 
            "text": "Slides 1  Slides 2", 
            "title": "CLC Genomics"
        }
    ]
}